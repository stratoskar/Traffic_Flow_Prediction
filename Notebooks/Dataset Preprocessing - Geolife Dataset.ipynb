{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e8e5b1",
   "metadata": {},
   "source": [
    "### This notebook process the initial dataset, in order to extract usefull information from it. \n",
    "\n",
    "In this dataset there are trajectories from 181 users. Only 69 of them have labeled their trajectories as Taxi, Car, Bus , Train, Subway and Walk. We are interested only in vehicle trajectories labeled as <b>Taxi</b>, <b>Car</b> and <b>Bus</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c485a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-05-03 20:57:46 +03:00)\n"
     ]
    }
   ],
   "source": [
    "# measure execution time\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae390b8",
   "metadata": {},
   "source": [
    "### Delete all folders, which contain unlabeled trajectories. We keep only the trajectories that are labeled.\n",
    "\n",
    "Prefered labels are: Car, Bus and Taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372e57ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remained folders is:  69\n",
      "time: 3.45 s (started: 2023-05-02 02:12:30 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# define the path in which data are stored\n",
    "path = 'C:/Users/SK/Desktop/Πτυχιακή/Σύνολα Δεδομένων/Geolife Trajectories 1.3/Data'\n",
    "\n",
    "# measure number of folders that remained after deletion\n",
    "counter = 0 \n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if (os.path.isfile(path+'/'+filename+'/labels.txt') == False):\n",
    "        shutil.rmtree(path+'/'+filename) # remove\n",
    "    else:\n",
    "        counter += 1 # keep remained folders in path\n",
    "\n",
    "print(\"Number of remained folders is: \",counter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4a65ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.8 s (started: 2023-05-02 02:12:34 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    # read the file labels.txt of each folder\n",
    "    label = pd.read_csv(path+'/'+filename+'/labels.txt',sep='\\t',names=['Start Time','End Time','Transportation Mode'])\n",
    "    \n",
    "    # keep only necessary labels\n",
    "    label = label[(label['Transportation Mode'] == 'car') | (label['Transportation Mode'] == 'bus') | (label['Transportation Mode'] == 'taxi')]\n",
    "    \n",
    "    # save the new file with the same name in the same folder (file replacion with the necessary information only)\n",
    "    path_to_be_saved = path+'/'+filename+'/labels.txt'\n",
    "    label.to_csv(path_to_be_saved,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a656ac",
   "metadata": {},
   "source": [
    "### Make the trajectory dataset\n",
    "Add in a new dataframe only the information of the trajecotries that we are interested in. This information refers to:\n",
    "\n",
    "-  <b>File ID:</b> The ID number of the folder, in which the information was teken.\n",
    "-  <b>Latitude:</b> The latitude of the GPS point.\n",
    "-  <b>Longitude:</b> The longitude of the GPS point.\n",
    "-  <b>Date Time:</b> Timestamp, in which the GPS was recorded.\n",
    "-  <b>Label:</b> This field contains one of the following values - Taxi, Bus or Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4440e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in folder 010 have been proccessed!\n",
      "Files in folder 020 have been proccessed!\n",
      "Files in folder 021 have been proccessed!\n",
      "Files in folder 052 have been proccessed!\n",
      "Files in folder 053 have been proccessed!\n",
      "Files in folder 056 have been proccessed!\n",
      "Files in folder 058 have been proccessed!\n",
      "Files in folder 062 have been proccessed!\n",
      "Files in folder 064 have been proccessed!\n",
      "Files in folder 065 have been proccessed!\n",
      "Files in folder 067 have been proccessed!\n",
      "Files in folder 068 have been proccessed!\n",
      "Files in folder 069 have been proccessed!\n",
      "Files in folder 073 have been proccessed!\n",
      "Files in folder 075 have been proccessed!\n",
      "Files in folder 076 have been proccessed!\n",
      "Files in folder 078 have been proccessed!\n",
      "Files in folder 080 have been proccessed!\n",
      "Files in folder 081 have been proccessed!\n",
      "Files in folder 082 have been proccessed!\n",
      "Files in folder 084 have been proccessed!\n",
      "Files in folder 085 have been proccessed!\n",
      "Files in folder 086 have been proccessed!\n",
      "Files in folder 088 have been proccessed!\n",
      "Files in folder 089 have been proccessed!\n",
      "Files in folder 091 have been proccessed!\n",
      "Files in folder 092 have been proccessed!\n",
      "Files in folder 096 have been proccessed!\n",
      "Files in folder 098 have been proccessed!\n",
      "Files in folder 100 have been proccessed!\n",
      "Files in folder 101 have been proccessed!\n",
      "Files in folder 102 have been proccessed!\n",
      "Files in folder 104 have been proccessed!\n",
      "Files in folder 105 have been proccessed!\n",
      "Files in folder 106 have been proccessed!\n",
      "Files in folder 108 have been proccessed!\n",
      "Files in folder 110 have been proccessed!\n",
      "Files in folder 111 have been proccessed!\n",
      "Files in folder 112 have been proccessed!\n",
      "Files in folder 114 have been proccessed!\n",
      "Files in folder 115 have been proccessed!\n",
      "Files in folder 118 have been proccessed!\n",
      "Files in folder 124 have been proccessed!\n",
      "Files in folder 125 have been proccessed!\n",
      "Files in folder 126 have been proccessed!\n",
      "Files in folder 128 have been proccessed!\n",
      "Files in folder 129 have been proccessed!\n",
      "Files in folder 138 have been proccessed!\n",
      "Files in folder 139 have been proccessed!\n",
      "Files in folder 141 have been proccessed!\n",
      "Files in folder 144 have been proccessed!\n",
      "Files in folder 147 have been proccessed!\n",
      "Files in folder 153 have been proccessed!\n",
      "Files in folder 154 have been proccessed!\n",
      "Files in folder 161 have been proccessed!\n",
      "Files in folder 163 have been proccessed!\n",
      "Files in folder 167 have been proccessed!\n",
      "Files in folder 174 have been proccessed!\n",
      "Files in folder 175 have been proccessed!\n",
      "Files in folder 179 have been proccessed!\n",
      "time: 1h 55min 8s (started: 2023-05-02 02:12:37 +03:00)\n"
     ]
    }
   ],
   "source": [
    "# make empty dataframe, in which all the data used for our research will be saved\n",
    "all_data = pd.DataFrame(columns = ['File ID','Latitude','Longitude','Date Time','Label']) \n",
    "\n",
    "id = 0 # trajectory ID\n",
    "\n",
    "for directory in os.listdir(path):\n",
    "\n",
    "    # read label.txt file of folder\n",
    "    labels = pd.read_csv(path+'/'+directory+'/'+'labels.txt',sep='\\t',names=['Start Time','End Time','Transportation Mode'],skiprows=[0])\n",
    "    \n",
    "    if (labels.shape[0] != 0):\n",
    "        \n",
    "        # temporary dataframe\n",
    "        directory_data = pd.DataFrame(columns = ['File ID','Latitude','Longitude','Date Time','Label'])\n",
    "\n",
    "        # convert datetime in labels.txt file to necessary format\n",
    "        labels['Start Time'] = pd.to_datetime(labels['Start Time'],format='%Y-%m-%d %H:%M:%S.%f')\n",
    "        labels['End Time'] = pd.to_datetime(labels['End Time'],format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "        for filename in os.listdir(path+'/'+directory+'/'+'Trajectory'): # for each folder\n",
    "\n",
    "            # read data file\n",
    "            data = pd.read_csv(path+'/'+directory+'/'+'Trajectory'+'/'+filename,skiprows=[0,1,2,3,4,5],sep=',',names=['Latitude','Longitude','Field 0','Altitude','Days Passed','Date','Time'])\n",
    "\n",
    "            # drop unecessary columns from data file\n",
    "            data.drop(['Days Passed','Altitude','Field 0'],axis=1,inplace=True)\n",
    "\n",
    "            # join time information to one column\n",
    "            data['Date Time'] = data['Date']+' '+data['Time']\n",
    "            data['Date Time'] = pd.to_datetime(data['Date Time'],format='%Y-%m-%d %H:%M:%S.%f')\n",
    "            data.drop(['Date','Time'],axis=1,inplace=True)\n",
    "\n",
    "            # add the ID of the trajectory\n",
    "            data.insert(0,'File ID',id)\n",
    "\n",
    "            directory_data = pd.concat([directory_data, data],ignore_index = True)\n",
    "            \n",
    "            id += 1\n",
    "        \n",
    "        # assign the label to each trajectory of the specific folder\n",
    "        for y in range(labels.shape[0]):\n",
    "            directory_data.loc[(directory_data['Date Time'] >= labels['Start Time'][y]) & (directory_data['Date Time'] <= labels['End Time'][y]),'Label'] = labels['Transportation Mode'][y] \n",
    "        \n",
    "        directory_data.dropna(axis=0,inplace=True)\n",
    "        \n",
    "        all_data = pd.concat([all_data, directory_data],ignore_index = True)\n",
    "        \n",
    "        print(\"Files in folder \"+str(directory)+\" have been proccessed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0eee5",
   "metadata": {},
   "source": [
    "### Process the dataset\n",
    "\n",
    "In this dataset, there are GPS information from many cities of China. The majority of those GPS records are located in the city of Beijing. We focus only in this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06cd7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 172 ms (started: 2023-05-02 10:27:12 +03:00)\n"
     ]
    }
   ],
   "source": [
    "# keep only GPS points from the city of Beijing\n",
    "all_data = all_data[(all_data['Latitude'] >= 39.8) & (all_data['Longitude'] >= 116.1)]\n",
    "\n",
    "# add a new column, which indicates the ID of each trajectory\n",
    "all_data.insert(1,'Traj ID',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09817ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to file\n",
    "all_data.to_csv('C:/Users/SK/Desktop/Πτυχιακή/Σύνολα Δεδομένων/Geolife Trajectories 1.3/all_original.txt',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976811f3",
   "metadata": {},
   "source": [
    "### Split the trajectories based in time field and FIle ID\n",
    "\n",
    "Split each trajectory in the same File ID based in the timestamp field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd66580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamp field to datetime\n",
    "all_data['Date Time'] = pd.to_datetime(all_data['Date Time'],format='%Y-%m-%d %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad1d472e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m traj_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(all_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile ID\u001b[39m\u001b[38;5;124m'\u001b[39m][i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile ID\u001b[39m\u001b[38;5;124m'\u001b[39m][i]): \u001b[38;5;66;03m# belong to the same File ID\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (((all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate Time\u001b[39m\u001b[38;5;124m'\u001b[39m][i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m-\u001b[39m(all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate Time\u001b[39m\u001b[38;5;124m'\u001b[39m][i]))\u001b[38;5;241m.\u001b[39mtotal_seconds() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m): \u001b[38;5;66;03m# time interval less-equal than 15sec\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Each File ID contains GPS data of one trajectory\n",
    "\n",
    "If the time gap between two GPS points is lower than 15 seconds, (condition 1)\n",
    "and these GPS points belong to the same File ID  (condition 2)\n",
    "then asign the same Traj ID number. (result)\n",
    "\n",
    "If the time gap between two GPS points is higher than 15 seconds, (condition 1)\n",
    "and these GPS points belong to the same File ID  (condition 2)\n",
    "then asign different Traj ID number to each of these GPS points. (result)\n",
    "\n",
    "If the GPS points belong to the same File ID  (condition 2)\n",
    "then asign different Traj ID number to each of these GPS points. (result)\n",
    "\n",
    "'''\n",
    "\n",
    "traj_id = 0\n",
    "\n",
    "for i in range(all_data.shape[0] -1):\n",
    "    \n",
    "    if (all_data['File ID'][i+1] == all_data['File ID'][i]): # belong to the same File ID\n",
    "        \n",
    "        if (((all_data['Date Time'][i+1])-(all_data['Date Time'][i])).total_seconds() <= 15): # time interval less-equal than 15sec\n",
    "            all_data.at[i,'Traj ID'] = traj_id\n",
    "            all_data.at[i+1,'Traj ID'] = traj_id\n",
    "            \n",
    "        else: # time interval higher than 15sec\n",
    "            all_data.at[i,'Traj ID'] = traj_id\n",
    "            traj_id +=1\n",
    "            all_data.at[i+1,'Traj ID'] = traj_id\n",
    "    \n",
    "    else: # not belong to the same File ID\n",
    "        all_data.at[i,'Traj ID'] = traj_id\n",
    "        traj_id  = 0\n",
    "        all_data.at[i+1,'Traj ID'] = traj_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa293ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data (with information of splitted trajectories)\n",
    "all_data.to_csv('C:/Users/SK/Desktop/Πτυχιακή/Σύνολα Δεδομένων/Geolife Trajectories 1.3/all_broken_trajectories.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bd0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalytics",
   "language": "python",
   "name": "dataanalytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
