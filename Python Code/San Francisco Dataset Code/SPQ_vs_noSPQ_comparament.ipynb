{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a619be0d",
   "metadata": {},
   "source": [
    "In this section of the code, we compare the two time series datasets that we created before. The first dataset contained the traffic flow information per path with respect to the rules of Strict Path Queries (SPQ), while the second time series dataset contains the raw traffic flow information per path, without the use of the SPQs.\n",
    "\n",
    "<b>Note, the definition of the Strict Path Queries is in the following link:</b>https://dl.acm.org/doi/abs/10.1145/2666310.2666413"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88532f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.39 s (started: 2023-08-03 13:36:07 +03:00)\n"
     ]
    }
   ],
   "source": [
    "# measure execution time\n",
    "%load_ext autotime\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# standard library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9943aba0",
   "metadata": {},
   "source": [
    "### Phase 3: Compare the time series datasets\n",
    "In this step, the following commands are executed:\n",
    "- Load the two time series datasets\n",
    "- Preprocess the datasets\n",
    "- Visualize the aggregated traffic flow information per timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52419d6",
   "metadata": {},
   "source": [
    "#### Step 1: Load the time series traffic flow datasets\n",
    "In this step we are doing the following operations:\n",
    "- Read the data\n",
    "- Change the name of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf07409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the two datasets\n",
    "time_series_SPQ = pd.read_csv('C:/Users/SK/Desktop/Πτυχιακή/Files/time_series.txt')\n",
    "time_series_no_SPQ = pd.read_csv()\n",
    "\n",
    "# this list contains the column names\n",
    "columns = [\"Taxi ID\",\"Traj ID\",\"Path\",\"Length\"]\n",
    "\n",
    "# generate the columns of the datasets\n",
    "i =4\n",
    "while(True):\n",
    "    if i == 4:\n",
    "        columns.append(pd.to_datetime('2008-05-18 00:00:00'))\n",
    "    else:\n",
    "        columns.append(columns[i-1] + timedelta(seconds=1800))\n",
    "    \n",
    "    if (columns[i]>=pd.to_datetime('2008-05-24 23:59:59.000130')):\n",
    "        break\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "# delete the last timestamp\n",
    "columns.pop()\n",
    "\n",
    "# assign new column names to our dataframes\n",
    "time_series_SPQ.columns = columns\n",
    "time_series_no_SPQ.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7982c8",
   "metadata": {},
   "source": [
    "#### Step 2: Preprocess the time series datasets\n",
    "In this step we are doing the following operations:\n",
    "- Reshape them to long format using melt function\n",
    "- Preprocess the data types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of columns that will be used as identifiers during the melt operation\n",
    "id_cols = ['Taxi ID','Traj ID', 'Path', 'Length']\n",
    "\n",
    "# apply melt function to the first dataset (time_series_SPQ)\n",
    "# get the column names from the third column onwards as time_cols\n",
    "time_cols = time_series_SPQ.iloc[:,2:].columns\n",
    "\n",
    "# perform the melt operation on the first dataset\n",
    "# it reshapes the dataframe from wide format to long format, \n",
    "# keeping the columns in id_cols as identifiers, and the rest of the columns in time_cols are melted into two new columns.\n",
    "time_series_SPQ = time_series_SPQ.melt(id_vars=id_cols, value_vars=time_cols, var_name='Time Column', value_name='Traffic Flow')\n",
    "\n",
    "# convert the 'Time Column' to datetime format to handle time-related data\n",
    "time_series_SPQ['Time Column'] = pd.to_datetime(time_series_SPQ['Time Column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply melt function to the second dataset (time_series_no_SPQ)\n",
    "# re-define the id_cols since the previous id_cols were modified in the first melt operation\n",
    "id_cols = ['Taxi ID','Traj ID', 'Path', 'Length']\n",
    "\n",
    "# get the column names from the third column onwards as time_cols for the second dataset\n",
    "time_cols = time_series_no_SPQ.iloc[:,2:].columns\n",
    "\n",
    "# perform the melt operation on the second dataset\n",
    "# similar to the previous melt operation, it reshapes the dataframe from wide format to long format.\n",
    "time_series_no_SPQ = time_series_no_SPQ.melt(id_vars=id_cols, value_vars=time_cols, var_name='Time Column', value_name='Traffic Flow')\n",
    "\n",
    "# convert the 'Time Column' to datetime format for the second dataset\n",
    "time_series_no_SPQ['Time Column'] = pd.to_datetime(time_series_no_SPQ['Time Column'])\n",
    "\n",
    "# sort rows by 'Path' and 'Time Column' for both datasets in ascending order\n",
    "time_series_SPQ.sort_values(by=['Path','Time Column'], inplace=True)\n",
    "time_series_no_SPQ.sort_values(by=['Path','Time Column'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664301d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index of the 'time_series_SPQ' DataFrame, \n",
    "# which converts the index into a regular column and reassigns a new integer index.\n",
    "time_series_SPQ = time_series_SPQ.reset_index()\n",
    "\n",
    "# rename the column 'index' to 'Time Column'.\n",
    "# this operation is helpful if the 'index' column has a meaningful name or represents some time-related information.\n",
    "time_series_SPQ.rename(columns={'index': 'Time Column'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index of the 'time_series_no_SPQ' DataFrame.\n",
    "# it converts the index into a regular column and reassigns a new integer index.\n",
    "time_series_no_SPQ = time_series_no_SPQ.reset_index()\n",
    "\n",
    "# rename the column 'index' to 'Time Column' in 'time_series_no_SPQ'.\n",
    "# this operation is helpful if the 'index' column has a meaningful name or represents some time-related information.\n",
    "time_series_no_SPQ.rename(columns={'index': 'Time Column'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d2361",
   "metadata": {},
   "source": [
    "#### Step 3: Extract timestamp information to different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the hour from the 'Time Column' and create a new column 'hour' in the 'time_series_SPQ' DataFrame.\n",
    "time_series_SPQ['hour'] = time_series_SPQ['Time Column'].dt.hour\n",
    "\n",
    "# extract the day of the week (0: Monday, 1: Tuesday, ..., 6: Sunday) from the 'Time Column' \n",
    "# and create a new column 'dayofweek' in the 'time_series_SPQ' DataFrame.\n",
    "time_series_SPQ['dayofweek'] = time_series_SPQ['Time Column'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae610e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the hour from the 'Time Column' and create a new column 'hour' in the 'time_series_no_SPQ' DataFrame.\n",
    "time_series_no_SPQ['hour'] = time_series_no_SPQ['Time Column'].dt.hour\n",
    "\n",
    "# extract the day of the week (0: Monday, 1: Tuesday, ..., 6: Sunday) from the 'Time Column' \n",
    "# and create a new column 'dayofweek' in the 'time_series_no_SPQ' DataFrame.\n",
    "time_series_no_SPQ['dayofweek'] = time_series_no_SPQ['Time Column'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e48c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom function to determine the three-hour interval, based in timestamp hour information\n",
    "def get_3hour_interval(hour):\n",
    "    if hour in [0, 1, 2]:\n",
    "        return 1\n",
    "    elif hour in [3, 4, 5]:\n",
    "        return 2\n",
    "    elif hour in [6, 7, 8]:\n",
    "        return 3\n",
    "    elif hour in [9, 10, 11]:\n",
    "        return 4\n",
    "    elif hour in [12, 13, 14]:\n",
    "        return 5\n",
    "    elif hour in [15, 16, 17]:\n",
    "        return 6\n",
    "    elif hour in [18, 19, 20]:\n",
    "        return 7\n",
    "    elif hour in [21, 22, 23]:\n",
    "        return 8\n",
    "    else:\n",
    "        return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ec71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the custom function on the \"time_series_SPQ\" data to create the '3hour_interval' column\n",
    "time_series_SPQ['3hour_interval'] = time_series_SPQ['hour'].apply(get_3hour_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b61779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the custom function on the \"time_series_no_SPQ\" data to create the '3hour_interval' column\n",
    "time_series_no_SPQ['3hour_interval'] = time_series_no_SPQ['hour'].apply(get_3hour_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03ad72",
   "metadata": {},
   "source": [
    "#### Step 4: Make Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea6ca1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.84 s (started: 2023-08-03 13:54:41 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a43d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by the 'Time Column' (timestamp/index) and calculate the sum of the 'Traffic Flow' \n",
    "# for each timestamp in the 'time_series_SPQ' DataFrame.\n",
    "grouped_df_SPQ = time_series_SPQ['Traffic Flow'].groupby(time_series_SPQ['Time Column']).sum()\n",
    "\n",
    "# convert the resulting Series to a DataFrame, with the timestamp (index) as a new column.\n",
    "grouped_df_SPQ = pd.DataFrame(grouped_df_SPQ, index=grouped_df_SPQ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ef559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by the 'Time Column' (timestamp/index) and calculate the sum of the 'Traffic Flow' \n",
    "# for each timestamp in the 'time_series_no_SPQ' DataFrame.\n",
    "grouped_df_no_SPQ = time_series_no_SPQ['Traffic Flow'].groupby(time_series_no_SPQ['Time Column']).sum()\n",
    "\n",
    "# convert the resulting Series to a DataFrame, with the timestamp (index) as a new column.\n",
    "grouped_df_no_SPQ = pd.DataFrame(grouped_df_no_SPQ, index=grouped_df_no_SPQ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc486327",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add additional time information to the 'grouped_df_SPQ' DataFrame based on the index (timestamp). ###\n",
    "\n",
    "# extract the hour from the timestamp (index) and create a new column 'hour'.\n",
    "grouped_df_SPQ['hour'] = grouped_df_SPQ.index.hour\n",
    "\n",
    "# apply the function 'get_3hour_interval' to create a new column '3hour_interval'.\n",
    "# the function likely maps each hour to a corresponding 3-hour interval or time block.\n",
    "grouped_df_SPQ['3hour_interval'] = grouped_df_SPQ['hour'].apply(get_3hour_interval)\n",
    "\n",
    "# extract the day of the week (0: Monday, 1: Tuesday, ..., 6: Sunday) from the timestamp (index) \n",
    "# and create a new column 'dayofweek'.\n",
    "grouped_df_SPQ['dayofweek'] = grouped_df_SPQ.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b456fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add additional time information to the 'grouped_df_no_SPQ' DataFrame based on the index (timestamp). ###\n",
    "\n",
    "# extract the hour from the timestamp (index) and create a new column 'hour'.\n",
    "grouped_df_no_SPQ['hour'] = grouped_df_no_SPQ.index.hour\n",
    "\n",
    "# apply the function 'get_3hour_interval' to create a new column '3hour_interval'.\n",
    "# the function likely maps each hour to a corresponding 3-hour interval or time block.\n",
    "grouped_df_no_SPQ['3hour_interval'] = grouped_df_no_SPQ['hour'].apply(get_3hour_interval)\n",
    "\n",
    "# extract the day of the week (0: Monday, 1: Tuesday, ..., 6: Sunday) from the timestamp (index) \n",
    "# and create a new column 'dayofweek'.\n",
    "grouped_df_no_SPQ['dayofweek'] = grouped_df_no_SPQ.index.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765d956",
   "metadata": {},
   "source": [
    "##### The code below creates a line plot to visualize the trend of total traffic flow over time in the 'SPQ' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom dark color palette with 8 colors using Seaborn's color_palette function.\n",
    "dark_palette = sns.color_palette('dark', n_colors=8)\n",
    "\n",
    "# create a plot to visualize the results.\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.lineplot(data=grouped_df_SPQ, x=grouped_df_SPQ.index, y='Traffic Flow', hue='dayofweek', marker='o', palette=dark_palette, linewidth=2.5)\n",
    "\n",
    "# set the labels for the x-axis and y-axis.\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total Traffic Flow')\n",
    "\n",
    "# set the title for the plot.\n",
    "plt.title('SPQ dataset: Traffic Flow Trends by Day of Week')\n",
    "\n",
    "# set the legend title.\n",
    "plt.legend(title='Day of Week', loc='upper right', labels=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a9ebb7",
   "metadata": {},
   "source": [
    "##### The code below creates a line plot to visualize the trend of total traffic flow over time in the 'No SPQ' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom dark color palette with 8 colors using Seaborn's color_palette function.\n",
    "dark_palette = sns.color_palette('dark', n_colors=8)\n",
    "\n",
    "# create a plot to visualize the results.\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.lineplot(data=grouped_df_no_SPQ, x=grouped_df_no_SPQ.index, y='Traffic Flow', hue='dayofweek', marker='o', palette=dark_palette, linewidth=2.5)\n",
    "\n",
    "# set the labels for the x-axis and y-axis.\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total Traffic Flow')\n",
    "\n",
    "# set the title for the plot.\n",
    "plt.title('No SPQ dataset: Traffic Flow Trends by Day of Week')\n",
    "\n",
    "# set the legend title.\n",
    "plt.legend(title='Day of Week', loc='upper right', labels=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371aeb7",
   "metadata": {},
   "source": [
    "##### The code below creates a plot to visualize the sum of traffic flow over time for two datasets: grouped_df_SPQ and grouped_df_no_SPQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot to visualize the results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# plot the sum of traffic flow over time for 'grouped_df_SPQ' dataset\n",
    "sns.lineplot(data=grouped_df_SPQ, x=grouped_df_SPQ.index, y='Traffic Flow', marker='o', linewidth=2.5, label='Dataset with SPQ')\n",
    "\n",
    "# plot the sum of traffic flow over time for 'grouped_df_no_SPQ' dataset\n",
    "sns.lineplot(data=grouped_df_no_SPQ, x=grouped_df_no_SPQ.index, y='Traffic Flow', marker='o', linewidth=2.5, alpha=0.7, label='Dataset without SPQ')\n",
    "\n",
    "# set the labels for the x-axis and y-axis\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sum of Traffic Flow')\n",
    "\n",
    "# set the title for the plot\n",
    "plt.title('Sum of Traffic Flow in Every Path Over Time')\n",
    "\n",
    "# add a legend to distinguish between the two datasets\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalytics",
   "language": "python",
   "name": "dataanalytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
